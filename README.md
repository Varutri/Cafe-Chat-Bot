RAG-Based Chatbot for a CafÃ©
Objective:
Develop a chatbot that answers questions about:
-Shop timings
-Menu items
-Meal costs
-Meal suggestions based on preferences
Requirements:
-Use a small document store (FAQs, menu, hours).
-Implement retrieval using FAISS or ChromaDB.
-Use a lightweight LLM (MiniLM, DistilBERT) for generation.
-Deploy via CLI or web interface (Gradio, Streamlit).
Skills Tested:
-Embedding and retrieval
-LLM integration
-Bot interface design


PROCESS FOLLOWED FOR CREATING EXTERNAL KNOWLEDGE BASE:- 





<img width="241" height="261" alt="image" src="https://github.com/user-attachments/assets/b0598344-6fc5-4bce-a312-a000402fca6c" />

















First Photo of my chat bot that also works as a RLHF (REINFORCEMENT LEARNING with HUMAN FEEDBACK)








<img width="509" height="422" alt="image" src="https://github.com/user-attachments/assets/f96043a3-8bdb-43e0-82c0-beb498b9586e" />




















Second Photo










<img width="518" height="405" alt="image" src="https://github.com/user-attachments/assets/2b794d8b-80c9-4a9f-89fa-ae06b1a9f06d" />





















After updating the prompt 











<img width="474" height="305" alt="image" src="https://github.com/user-attachments/assets/5f72975b-28cb-46e5-99b7-d3e9f8e6724c" />










































How I Built My CafÃ© Chatbot Using RAG (Retrieval-Augmented Generation)

It all started with a simple idea:
"Wouldnâ€™t it be cool if a cafÃ© could have a chatbot that not only answers FAQs like opening hours, but also recommends dishes, understands customer preferences, and gives natural, human-like responses?"

At first, it sounded simple. But the deeper I went, the more I realized â€” building a smart assistant is not just about plugging in an LLM. Itâ€™s about designing a pipeline where every step works together like gears in a machine.

ğŸ—ï¸ Step 1: Building the Knowledge Base

The cafÃ© had three sources of truth:

Menu items ğŸ°

Order history ğŸ“Š

FAQs â“

I combined them into a document store where each entry had both text and metadata (like number of orders or average rating).

ğŸ‘‰ Why?
Because customers donâ€™t just want to know what a â€œLatteâ€ is â€” they want to know if itâ€™s popular, if people like it, and if it matches their preferences. So metadata became just as important as raw text.

ğŸ§  Step 2: Choosing the Right Embeddings

For dense embeddings, I picked MiniLM (all-MiniLM-L6-v2).

ğŸ‘‰ Why MiniLM?

Lightweight and super-fast âš¡

Captures semantic meaning well (great balance of performance vs accuracy)

Works beautifully with FAISS indexing

Every document and FAQ was preprocessed, lemmatized, and encoded into embeddings. To make it stronger, I even added data augmentation (synonym replacement, back translation, and T5-based paraphrasing).

This ensured that no matter how a customer phrased their query â€” â€œTell me about cappuccinoâ€ vs â€œWhat is a cappuccino?â€ â€” the chatbot would still retrieve the right info.

ğŸ” Step 3: Indexing with FAISS

I needed a fast way to search through vectors, so I used FAISS with Inner Product (IP).

ğŸ‘‰ Why Inner Product?
Because I normalized all embeddings, inner product â‰ˆ cosine similarity.
This meant retrieval was quick and accurate, without being biased toward longer vectors.

Saving metadata alongside vectors ensured that when I retrieved results, I could still reference whether the doc was an FAQ, menu item, or something else.

ğŸ¯ Step 4: Retrieval â€“ Going Hybrid

Hereâ€™s where I hit a challenge.
Dense embeddings are great at capturing semantic meaning, but sometimes customers ask keyword-heavy queries.

Example:
â€œDo you serve gluten-free muffins?â€

Dense search might not always pick this up if â€œgluten-freeâ€ is rare.

So I introduced a Hybrid Retriever:

Dense search via FAISS

Sparse search via TF-IDF

Weighted combination of both

ğŸ‘‰ Why Hybrid?
Because I didnâ€™t want my bot to miss obvious keywords. This gave me the best of both worlds: understanding semantics and exact matches.

â­ Step 5: Recommendations

I didnâ€™t want the bot to just answer questions. I wanted it to recommend dishes like a real barista.

So I built a hybrid recommender that combined:

Semantic similarity (what you typed)

Popularity (number of orders)

Ratings (average feedback)

ğŸ‘‰ Why?
Because if 90% of customers love our cappuccino, the bot should be smart enough to nudge you toward it â€” while still respecting your preferences like â€œI want something light and sweet.â€

ğŸ“Œ Step 6: Reranking with CrossEncoder

Retrieval gave me candidates, but I wanted precision. Thatâ€™s where I used a Cross-Encoder (MiniLM Cross-Encoder) to rerank results.

ğŸ‘‰ Why Reranker?
Because dense retrieval is like â€œguessing which shelves to check in a library,â€ while reranking is like â€œreading those books to see which really answers the question.â€

This step made the bot far more accurate and reliable.

ğŸ’¡ Step 7: Response Generation

For natural answers, I chose FLAN-T5-small.

ğŸ‘‰ Why FLAN-T5?

Lightweight, runs fast even on CPU

Strong at instruction-following

Generates polite, human-like responses

I crafted prompts carefully to control tone:

Always give 2â€“5 sentences

Be helpful and friendly

Personalize with user preferences

This ensured responses didnâ€™t sound robotic. Instead, they felt like a real cafÃ© assistant.

ğŸ¨ Step 8: Building the Frontend

Finally, I wrapped everything in a Streamlit app.

A clean interface for customers to chat

Sidebar for adding preferences (vegetarian, spicy, budget)

Feedback logging to improve responses

ğŸš€ The Result

The cafÃ© chatbot could now:
âœ”ï¸ Answer FAQs like timings, menu items, or ingredients
âœ”ï¸ Recommend dishes based on popularity, rating, and your taste
âœ”ï¸ Personalize responses with preferences
âœ”ï¸ Provide natural, friendly explanations

All of this was powered by RAG (Retrieval-Augmented Generation), carefully designed to balance speed, accuracy, and usability.

âœ¨ What I Learned

Embeddings matter â†’ MiniLM gave me the sweet spot of speed + accuracy.

Hybrid retrieval is powerful â†’ Never rely on just dense or sparse.

Rerankers bring precision â†’ They clean up noisy retrieval.

Small LLMs can be mighty â†’ FLAN-T5-small was more than enough for controlled generation.

Metadata is gold â†’ Popularity & ratings gave the bot â€œhumanâ€ intelligence.

ğŸ’­ Looking back, this project was more than building a chatbot. It was about designing an ecosystem where every component â€” indexer, retriever, recommender, reranker, generator â€” plays a unique role.

Thatâ€™s the beauty of RAG: itâ€™s not just about using an LLM, itâ€™s about teaching it where to look, how to rank, and how to talk.

ğŸ”¥ And thatâ€™s how my cafÃ© chatbot was born.
Now, whether a customer asks â€œWhatâ€™s your best latte?â€ or â€œI want something refreshing under $5â€â€¦ the bot knows exactly what to say.
